<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>News | Gallant Lab</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Cognitive, Systems and Computational Neuroscience at the Leading Edge"><meta name=generator content="Hugo 0.139.3"><meta name=robots content="index, follow"><link rel=stylesheet href=/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css><link href=/index.xml rel=alternate type=application/rss+xml title="Gallant Lab"><link href=/index.xml rel=feed type=application/rss+xml title="Gallant Lab"><link rel=canonical href=https://gallantlab.org/><meta property="og:url" content="https://gallantlab.org/"><meta property="og:site_name" content="Gallant Lab"><meta property="og:title" content="News"><meta property="og:description" content="Cognitive, Systems and Computational Neuroscience at the Leading Edge"><meta property="og:locale" content="en_us"><meta property="og:type" content="website"><meta itemprop=name content="News"><meta itemprop=description content="Cognitive, Systems and Computational Neuroscience at the Leading Edge"><meta itemprop=datePublished content="2025-12-17T00:00:00-08:00"><meta itemprop=dateModified content="2025-12-17T00:00:00-08:00"><meta itemprop=wordCount content="133"><meta name=twitter:card content="summary"><meta name=twitter:title content="News"><meta name=twitter:description content="Cognitive, Systems and Computational Neuroscience at the Leading Edge"><link rel=stylesheet href=/css/custom.min.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel=stylesheet></head><body class="ma0 avenir bg-near-white production"><div class=site-header-banner><div class=site-header-banner-content><div class=banner-left-text><div>Gallant</div><div>Lab</div></div><video autoplay loop muted playsinline class=header-banner-image>
<source src=/img/header-brain-mobile.mp4 type=video/mp4 media="(max-width: 768px)"><source src=/img/header-brain.mp4 type=video/mp4></video><div class=banner-right-text><div>at UC</div><div>Berkeley</div></div></div></div><header><nav class=pv3 role=navigation><div class="flex-l center items-center justify-between"><div class="flex-l items-center w-100"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/ title="News page">News</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/people/ title="People page">People</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/publications/ title="Publications page">Publications</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/brain-viewers/ title="Brain Viewers page">Brain Viewers</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/learn/ title="Learn page">Learn</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/code/ title="Code page">Code</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/data/ title="Data page">Data</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/joinus/ title="Join Us page">Join Us</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white white-90 no-underline" href=/blog/ title="Blog page">Blog</a></li></ul><div class=ananke-socials></div></div></div></nav></header><main class=pb7 role=main><article class="cf f4 center lh-copy nested-links nested-copy-line-height main-content"><p>This site provides information about ongoing research in Jack Gallant&rsquo;s cognitive, systems and computational neuroscience lab at UC Berkeley. Here you can find our cool interactive brain viewers, some of our published papers, information about the great people who do the work, our open data, open source code, and tutorials.</p><p>If you would like to know more about the general philosophy of the lab, please listen to this <a href=https://freakonomics.com/podcast/this-is-your-brain-on-podcasts/>Freakonomics podcast interview with Jack Gallant</a> or to these OHBM discussions between Peter Bandettini and Jack Gallant (<a href="https://www.youtube.com/watch?v=cKmGF3REyuA&amp;list=PLEJ899jsgdRoMWrUhwBsP7-R_DsfIkRFk&amp;index=5">discussion 1</a>, <a href="https://www.youtube.com/watch?v=skX7tzWxwFk">discussion 2</a>). If you would like to know more about our cutting-edge fMRI data analysis and modeling framework, voxelwise encoding models, please navigate to the <a href=/learn/>Learn page</a>.</p><h2 id=we-are-recruiting-postdocs>We are recruiting postdocs!</h2><p>We currently have openings for potential postdocs. If you are interested please contact <a href=/people/>Jack Gallant</a>.</p><h2>Latest News</h2><div class="news-item card fade-in"><div class=news-card-content><div class=news-card-image><img src=/img/papers/Zhang.T.navigation.webp alt="Zhang et al. Naturalistic Navigation fMRI study"></div><div class=news-card-text><p class=news-date>December 17, 2025</p><div class=news-description>Our awesome postdoc <a href=/people#tianjiao-zhang-phd>Dr. Tianjiao Zhang</a> has uploaded his Naturalistic Navigation study as a <a href=https://www.biorxiv.org/content/10.64898/2025.12.16.694742v1>preprint on bioRxiv</a>. Participants performed a taxi driver task in a large virtual world. Voxelwise encoding models were used to fit 38 different feature spaces (comprising an astounding 28,134 distinct features) to the data. Results show that naturalistic navigation is supported by a network of 11 functionally distinct cortical regions that operate together to transform perceptual inputs through decision-making processes to produce action outputs. This paper really pushes the boundaries of what is possible in fMRI, no one has ever done anything at this scale before.</div></div></div></div><div class="news-item card fade-in"><div class=news-card-content><div class=news-card-image><img src=/img/other/autoflatten.webp alt="Autoflatten cortical surface flattening" loading=lazy></div><div class=news-card-text><p class=news-date>December 15, 2025</p><div class=news-description>We've released <a href=https://github.com/gallantlab/autoflatten>Autoflatten</a>, a Python pipeline for automatically flattening cortical surfaces generated by FreeSurfer. Prior to the development of this pipeline flattening was done largely by hand, an incredibly time-consuming and frustrating process. This new pipeline automates most of the work. Thanks to <a href=/people#matteo-visconti-di-oleggio-castello-phd>Dr. Matteo Visconti di Oleggio Castello</a> for this great new tool!</div></div></div></div><div class="news-item card fade-in"><div class=news-card-content><div class=news-card-image><img src=/img/people/Amanda.LeBel.webp alt="Amanda LeBel" loading=lazy></div><div class=news-card-text><p class=news-date>December 8, 2025</p><div class=news-description><a href=/people#amanda-lebel>Amanda LeBel</a> has received her PhD! Congratulations Dr. LeBel! Amanda will be starting a postdoc in the lab of Prof. Anila D'Mello at UT Southwestern and UT Dallas early next year.</div></div></div></div><div class="news-item card fade-in"><div class=news-card-content><div class=news-card-image><img src=/img/people/Fatma.Deniz.webp alt="Fatma Deniz" loading=lazy></div><div class=news-card-text><p class=news-date>December 3, 2025</p><div class=news-description>Fantastic news! Our former postdoc <a href=/people#fatma-deniz-phd>Prof. Fatma Deniz</a> has just been elected President of the Technical University of Berlin! Congratulations President Deniz!</div></div></div></div><div class="news-item card fade-in"><div class=news-card-content><div class=news-card-image><img src=/img/papers/az.webp alt="Zeng and Gallant 2025 NeurIPS" loading=lazy></div><div class=news-card-text><p class=news-date>November 13, 2025</p><div class=news-description>This <a href="https://openreview.net/forum?id=3aNvX9TQTo">new NeurIPS paper</a> from <a href=/people#alicia-zeng>Alicia Zeng</a> presents an important new method for improving interpretation of neuroimaging experiments that use word embeddings as features.</div></div></div></div><div class="news-item card fade-in"><div class=news-card-content><div class=news-card-image><img src=/img/papers/ViscontidOC.Deniz.2025.webp alt="Visconti di Oleggio Castello et al. 2025 VEM framework" loading=lazy></div><div class=news-card-text><p class=news-date>September 17, 2025</p><div class=news-description>Our latest review paper on the Voxelwise Encoding Model (VEM) framework from <a href=/people#matteo-visconti-di-oleggio-castello-phd>Matteo Visconti di Oleggio Castello</a> and <a href=/people#fatma-deniz-phd>Fatma Deniz</a> is now available as a preprint on <a href=https://www.psyarxiv.com/nt2jq>PsyArXiv</a>. This paper provides the first comprehensive guide for creating encoding models with fMRI data, and complements our VEM tutorials.</div></div></div></div><div class="news-item card fade-in"><div class=news-card-content><div class=news-card-image><img src=/img/other/viewer.Huth.A.2012.webp alt="Group short movie clip semantic maps" loading=lazy></div><div class=news-card-text><p class=news-date>September 15, 2025</p><div class=news-description>We have created a new <a href=https://gallantlab.org/viewer-shortclips-group/>brain viewer</a> that provides a way to inspect cortical visual-semantic conceptual maps at the group level, vertex-by-vertex. The data for this viewer were generated by pooling visual semantic maps from 15 separate participants who viewed several hours of short movie clips.</div></div></div></div><p class=old-news-link>Find older news items <a href=/old-news/>here</a>.</p></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-center"><div class="f6 fw4 white-70 tc pv2 ph3">&copy; Copyright 2025 Jack Gallant.
And also by the Regents of the University of California, our benevolent overlords.
Powered by <a href=https://gohugo.io/ target=_blank class="white-70 hover-white">Hugo</a>.
Hosted by <a href=https://pages.github.com/ target=_blank class="white-70 hover-white">GitHub Pages</a>.
Last updated: December 18, 2025.</div></div></footer></body></html>
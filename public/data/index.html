<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=4001&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Data | Gallant Lab</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Open datasets from the Gallant Lab for neuroscience research">
    <meta name="generator" content="Hugo 0.152.0">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >




    


    
      

    

    

    
      <link rel="canonical" href="http://localhost:4001/data/">
    

    <meta property="og:url" content="http://localhost:4001/data/">
  <meta property="og:site_name" content="Gallant Lab">
  <meta property="og:title" content="Data">
  <meta property="og:description" content="Open datasets from the Gallant Lab for neuroscience research">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">

  <meta itemprop="name" content="Data">
  <meta itemprop="description" content="Open datasets from the Gallant Lab for neuroscience research">
  <meta itemprop="wordCount" content="532">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Data">
  <meta name="twitter:description" content="Open datasets from the Gallant Lab for neuroscience research">

	
<link rel="stylesheet" href="/css/custom.min.css" />


<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />

  </head><body class="ma0 avenir bg-near-white development">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <div class="flex-l items-center w-100">
      <a href="/" class="f3 fw7 hover-white white no-underline" style="margin-right: 2rem;">
        Gallant Lab
      </a>
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/people/" title="People page">
              People
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/publications/" title="Publications page">
              Publications
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/brain-viewers/" title="Brain Viewers page">
              Brain Viewers
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/learn/" title="Learn page">
              Learn
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/code/" title="Code page">
              Code
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/data/" title="Data page">
              Data
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/joinus/" title="Join Us page">
              Join Us
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/blog/" title="Blog page">
              Blog
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100"><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">Data</h1>
      
      
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l">    

<div class="publication-card card fade-in">
  <div class="publication-image">
    <a href="https://doi.gin.g-node.org/10.12751/g-node.vy1zjd/" target="_blank" rel="noopener noreferrer">
      <img src="/img/datasets/Popham.etal.2021.webp" alt="Gallant Lab Natural Short Clips fMRI Dataset" />
    </a>
  </div>
  <div class="publication-info">
    <h3 class="publication-title">
      <a href="https://doi.gin.g-node.org/10.12751/g-node.vy1zjd/" target="_blank" rel="noopener noreferrer">Natural Short Clips 3T fMRI Data</a>
    </h3>
    <div class="publication-description">This dataset contains BOLD fMRI responses from 5 human subjects viewing natural short video clips across 3 sessions over 3 separate days for each subject. This dataset has been used in multiple publications studying visual processing and semantic representation. If you publish work that uses these data please cite the following paper: <a href='https://doi.org/10.1038/s41593-021-00921-6'>Popham, S. F., Huth, A. G., Bilenko, N. Y., Deniz, F., Gao, J. S., Nunez-Elizalde, A. O., & Gallant, J. L. (2021). Visual and linguistic semantic representations are aligned at the border of human visual cortex. Nature Neuroscience, 24(11), 1628-1636.</a></div>
  </div>
</div>

    

<div class="publication-card card fade-in">
  <div class="publication-image">
    <a href="http://crcns.org/data-sets/vc/vim-4/about-vim-4" target="_blank" rel="noopener noreferrer">
      <img src="/img/datasets/Zhang.etal.2021.webp" alt="Gallant Lab Naturalistic fMRI Dataset" />
    </a>
  </div>
  <div class="publication-info">
    <h3 class="publication-title">
      <a href="http://crcns.org/data-sets/vc/vim-4/about-vim-4" target="_blank" rel="noopener noreferrer">Naturalistic fMRI Data (vim-4)</a>
    </h3>
    <div class="publication-description">This dataset contains whole-brain BOLD fMRI responses from human subjects performing two tasks: a visual attention task (passive movie watching with attention directed to humans or vehicles) and a video game task (open-ended Counterstrike gameplay). This dataset enables analysis of task-related cognitive states in naturalistic experimental conditions. If you publish work that uses these data please cite the following paper: <a href='https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2020.565976/full'>Zhang, T., Gao, J. S., Ã‡ukur, T., & Gallant, J. L. (2021). Voxel-based state space modeling recovers task-related cognitive states in naturalistic fmri experiments. Frontiers in neuroscience, 14, 565976.</a></div>
  </div>
</div>

    

<div class="publication-card card fade-in">
  <div class="publication-image">
    <a href="https://gin.g-node.org/denizenslab/narratives_reading_listening_fmri/src/master/chen2024_timescales" target="_blank" rel="noopener noreferrer">
      <img src="/img/datasets/Deniz.etal.2019.webp" alt="Gallant Lab Semantic Listening vs Reading fMRI Dataset" />
    </a>
  </div>
  <div class="publication-info">
    <h3 class="publication-title">
      <a href="https://gin.g-node.org/denizenslab/narratives_reading_listening_fmri/src/master/chen2024_timescales" target="_blank" rel="noopener noreferrer">Semantic Listening vs Reading fMRI Data</a>
    </h3>
    <div class="publication-description">This dataset contains BOLD fMRI responses from human subjects during listening and reading tasks, demonstrating that semantic information representation across cerebral cortex remains invariant to stimulus modality. This dataset enables investigation of cross-modal semantic processing in the brain. If you publish work that uses these data please cite the following paper: <a href='https://www.jneurosci.org/content/39/39/7722'>Deniz, F., Nunez-Elizalde, A. O., Huth, A. G., & Gallant, J. L. (2019). The representation of semantic information across human cerebral cortex during listening versus reading is invariant to stimulus modality. Journal of Neuroscience, 39(39), 7722-7736.</a></div>
  </div>
</div>

    

<div class="publication-card card fade-in">
  <div class="publication-image">
    <a href="https://gin.g-node.org/gallantlab/story_listening" target="_blank" rel="noopener noreferrer">
      <img src="/img/papers/Huth.A.2016.webp" alt="Gallant Lab Story Listening fMRI Dataset" />
    </a>
  </div>
  <div class="publication-info">
    <h3 class="publication-title">
      <a href="https://gin.g-node.org/gallantlab/story_listening" target="_blank" rel="noopener noreferrer">Story Listening fMRI Data</a>
    </h3>
    <div class="publication-description">This dataset contains BOLD fMRI responses from human subjects listening to natural narrative stories. This dataset was used to map semantic representations across the human cerebral cortex and create detailed semantic atlases of language processing. If you publish work that uses these data please cite the following paper: <a href='https://www.nature.com/articles/nature17637'>Huth, A. G., De Heer, W. A., Griffiths, T. L., Theunissen, F. E., & Gallant, J. L. (2016). Natural speech reveals the semantic maps that tile human cerebral cortex. Nature, 532(7600), 453-458.</a></div>
  </div>
</div>

    

<div class="publication-card card fade-in">
  <div class="publication-image">
    <a href="https://crcns.org/data-sets/vc/vim-2/about-vim-2" target="_blank" rel="noopener noreferrer">
      <img src="/img/datasets/Nishimoto.etal.2011.webp" alt="Gallant Lab Natural Movie fMRI Dataset" />
    </a>
  </div>
  <div class="publication-info">
    <h3 class="publication-title">
      <a href="https://crcns.org/data-sets/vc/vim-2/about-vim-2" target="_blank" rel="noopener noreferrer">Natural Movie 4T fMRI Data (vim-2)</a>
    </h3>
    <div class="publication-description">This dataset contains BOLD fMRI responses from 3 subjects viewing natural movies, collected across 3 sessions on separate days. This dataset was used in the landmark study reconstructing visual experiences from brain activity. If you publish work that uses these data please cite the following paper: <a href='https://www.sciencedirect.com/science/article/pii/S0960982211009377'>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu, B., & Gallant, J. L. (2011). Reconstructing visual experiences from brain activity evoked by natural movies. Current Biology, 21(19), 1641-1646.</a></div>
  </div>
</div>

    

<div class="publication-card card fade-in">
  <div class="publication-image">
    <a href="http://crcns.org/data-sets/vc/vim-1/about-vim-1" target="_blank" rel="noopener noreferrer">
      <img src="/img/datasets/Kay.etal.2008.webp" alt="Gallant Lab Natural Images fMRI Dataset" />
    </a>
  </div>
  <div class="publication-info">
    <h3 class="publication-title">
      <a href="http://crcns.org/data-sets/vc/vim-1/about-vim-1" target="_blank" rel="noopener noreferrer">Natural Images fMRI Data (vim-1)</a>
    </h3>
    <div class="publication-description">This dataset contains BOLD fMRI responses from 2 subjects viewing natural images across 70 experimental runs collected over 5 separate days. This dataset demonstrated the ability to identify which images a subject was viewing from brain activity using Bayesian reconstruction techniques. If you publish work that uses these data please cite the following paper: <a href='https://www.nature.com/articles/nature06713'>Kay, K. N., Naselaris, T., Prenger, R. J., & Gallant, J. L. (2008). Identifying natural images from human brain activity. Nature, 452(7185), 352-355.</a></div>
  </div>
</div>

<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-center">
    <div class="f6 fw4 white-70 tc pv2 ph3">
      &copy; Copyright 2025 Jack Gallant.
      And also by the Regents of the University of California, our benevolent overlords.
      Powered by <a href="https://gohugo.io/" target="_blank" class="white-70 hover-white">Hugo</a>.
      Hosted by <a href="https://pages.github.com/" target="_blank" class="white-70 hover-white">GitHub Pages</a>.
      
    </div>
  </div>
</footer>

  </body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>FMRI on Gallant Lab</title><link>https://gallantlab.org/tags/fmri/</link><description>Recent content in FMRI on Gallant Lab</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sat, 20 Dec 2025 00:00:00 -0800</lastBuildDate><atom:link href="https://gallantlab.org/tags/fmri/index.xml" rel="self" type="application/rss+xml"/><item><title>Learning and implementing Voxelwise Encoding Models: A guide to reviews, tutorials, and software</title><link>https://gallantlab.org/blog/2025-12-20-vem-guide/</link><pubDate>Sat, 20 Dec 2025 00:00:00 -0800</pubDate><guid>https://gallantlab.org/blog/2025-12-20-vem-guide/</guid><description>&lt;p&gt;Voxelwise Encoding Models (VEMs) are one of the most sensitive methods available for modeling and decoding functional brain activity. In the VEM framework, features are extracted from the stimulus (or task) and used in an encoding model to predict brain activity. If the encoding model is able to predict brain activity in some part of the brain, then one may conclude that some information represented in the features is also represented in the brain.&lt;/p&gt;</description></item></channel></rss>